---
title: 2. 模型评估与选择
date: 2021-06-09
categories: 
  - MachineLearning-周志华
tags:
  - readnotes
  - ml
---

## 2.1 经验误差与过拟合

通常我们把分类错误的样本数占样本总数的比例称为<span style="color:green">**错误率（error rate）**</span>，对应的  “1 - 错误率” 就是<span style="color:green">**精度（accuracy）**</span>。

更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为 “<span style="color:green">**误差（error）**</span>”，误差又分为：

- 在训练集上的“**训练误差**”或“**经验误差**”；
- 在新样本上的“**泛化误差**”；

由于事先并不知道新样本的数据，因此，实际能做的就是尽量减少在训练集上的经验误差。

但是，实际情况是，一个在训练集上表现十分优秀的学习器，在面对新样本时，往往泛化性能并不理想，这是因为出现了**过拟合（overfitting）**现象：当学习器把训练集学习得“太好”了，很可能把训练样本自身的一些特点当成了所有潜在样本都会具有的一般性质，导致泛化能力下降。俗称：“**以偏概全**”。过拟合通常是由于学习能力过强。

与“过拟合”相对的是“**欠拟合（underfitting）**”，这是指对训练样本的一般性质未学好。下图是一个直观的例子。

![image-20210629134512515](https://cdn.astero.xyz/img/image-20210629134512515.png)

显然，“欠拟合”是容易改善的，只要提高学习算法的学习能力，或者增加样本数等；而“过拟合”则难以避免。

> 关于这点，书中使用 $\Large{P \neq NP}$ 来解释为什么“过拟合”难以完全避免：机器学习试图解决的问题大多是$\Large{NP}$ 甚至 $\Large{NP-Hard}$ ，如果能通过经验误差最小化就能获取最优解，而机器学习的算法又必然是在多项式时间内完成的（且训练集是有限的），则构造性地证明了 $\Large{P = NP}$。
>
> 对此我的理解是：以减少经验误差为目的的最极端的过拟合莫过于只学习训练样本中的数据的机械学习，完全消除了经验误差；但是这样的模型并不是我们想要的，因为其“泛化误差”会非常大。所以实际情况种，经验误差小的学习算法不一定就是实用的，设计时不必过度追求减小经验误差。

## 2.2 评估方法

现实任务中，往往有多个学习算法可供选择；甚至对同一个学习算法，使用不同的参数配置时，也会产生不同的模型，这时就需要对模型进行评估（model selecting）。理想情况下：

- 对候选模型的泛化误差进行评估，选择泛化误差最小的模型。

但是，我们无法直接得到泛化误差，而训练误差由于过拟合的存在，也不适合作为评估标准。因此，引入了“**测试集**”和“测试误差”的概念。

测试集：

- 应当和训练集一样，从样本真实分布中独立同分布采样取得；
- 应当和训练集互斥；

在测试集上对模型的泛化能力进行测试，得到的误差即“测试误差”。

当我们的数据集 $\Large D$ 有限时，需要对其进行处理，从中提取出训练集 $\Large S$ 和测试集 $\Large T$，下面是几种做法。

### 2.2.1 留出法 Hold-out

“留出法”直接将 $\Large D$ 划分为两个互斥的集合，一个作为训练集 $\Large S$ ，一个作为测试集 $\Large T$。

需要注意的是，训练/测试集的划分要尽可能保证数据分布的一致性。例如分类任务中，需要保证各自样本中的各类别比例尽量一致（分层采样 stratified sampling）。

影响划分的因素还有很多，因此，单次留出法是不太靠谱的。:warning: 通常会采取多次随机划分，重复实验取平均值来作为留出法的评估结果。

另外，我们希望的是基于整个 $\Large D$ 进行训练，人为划分成训练集和测试集后，训练出的模型与直接用 $\Large D$ 训练出的模型肯定有差别。

- 若 $\Large S$ 较大，则用于评估的 $\Large T$ 较小，评估结果可能不准确，即方差较大；
- 若 $\Large S$ 较小，则训练出的模型可能和实际用 $\Large D$ 训练出的差别较大，降低了评估结果的保真性，即偏差较大；

这个问题也没有完美的解决方法，通常情况下：

<span style ="color:orange">将大约 </span> $\cfrac{2}{3} \sim \cfrac{4}{5}$ <span style="color:orange">的样本用于训练，剩余样本用于测试。且一般而言，测试集至少应包含30个样例。</span>

### 2.2.2 交叉验证法 Cross validation

将 $\Large D$ 划分为 $\Large k$ 个大小相似的互斥子集，即：$\Large D = D_1 \cup D_2 \; \cup \;... \;\cup \;D_k,\quad D_i \cap D_j = \varnothing \; (i \neq j)$ ，与留出法一样，每个子集尽量保持数据分布的一致性。

然后每次用 $\Large k-1$ 个子集的并作为训练集，余下的子集作为测试集进行训练和测试；这样经过 $\Large k$ 次训练/测试后得到的结果进行平均即可得到该学习算法的最终结果。

与留出法一样，在进行 $\Large k$ 个子集的划分时，也需要进行多次随机划分；假设随机划分的重复次数为 $\Large p$ ，则最终进行的是：
$$
\Large
\color{orange}
p次k折交叉验证
$$
假设 $\Large D$ 中包含 $\Large m$ 个样本，若 $\Large k = m$ ，即每个子集中只包含一个样本，此时是交叉验证法的一个特例——**留一法（Leave-One-Out LOO）**，通常情况下，留一法的评估结果被认为是比较准确的；但是也受 NFL 的限制，另外，当 $\Large m$ 较大时，训练成本可能非常高。

### 2.2.3 自助法 bootstrapping

在留出法和交叉验证法中，总是留出了一部分样本用于测试，使得训练集永远小于 $\Large D$ ，这必然引起偏差。而留一法的计算复杂度太高不实用，因此引入“**自助法**”。

自助法使用“自主采样”（也称可重复采样，可放回采样）为基础。

自主采样：

1. 给定包含 $\Large m$ 个样本的数据集 $\Large D$ ，每次从中随机选出一个样本，将其<span style="color:orange">**拷贝**</span>进训练集 $\Large S$ 中，然后将其放回 $\Large D$ 中；
2. 重复 $\Large m$ 次上述操作，将最终的 $\Large S$ 作为训练集， $ \Large D \setminus S$ 作为测试集。

这个过程中，某些样本可能会被取到多次，有的一次也没有取到，计算某样本始终没有取到的概率为 $\Large (1 - \cfrac1m)^m$ ，当 $\Large m \to \infty$ 时，取极限可得：
$$
\Large
\lim\limits_{m \to \infty}(1 - \cfrac1m)^m = \cfrac1e \approx 0.368
$$

> 证明：
> $$
> \cfrac{1}{(1 - \cfrac1m)^m} = \cfrac{1}{(\cfrac{m-1}{m})^m} 
> = (\cfrac{m}{m-1})^m 
> = (1 + \cfrac{1}{m-1})^m 
> = (1 + \cfrac{1}{m-1})^{m-1} \times (1 + \cfrac{1}{m-1})
> $$
> 已知：$\lim\limits_{n \to \infty}(1 + \cfrac1n)^n=e$ （自然对数的定义，可通过对两边取对数后求导验证），对 (3) 式两侧取极限可得：$\lim\limits_{m \to \infty}\cfrac{1}{(1 - \cfrac1m)^m} = e \times 1 = e$ ，(2)得证。

> 历史上应该是从微分方程 $ \cfrac{dy}{dx} = y$ 导出 $ e$ 的定义。[更多解释](https://www.zhihu.com/question/33689408)

这样，数据集 $\Large D$ 中的所有样本都参与了训练集和测试集的选取过程，根据概率，我们仍有约 $\large \cfrac 13$ 的数据用于测试。

自助法在数据集较小，难以划分时很有用；但是其产生的数据集改变了初始数据集的分布，引入了估计偏差。因此，**在初始数据量足够时，常用留出法和交叉验证法**。

### 2.2.4 调参与最终模型 parameter tuning

算法参数通常不多，但是模型参数巨多。:sweat:

尽管在训练和测试时，将数据集 $\Large D$ 分成了训练集和测试集，但是评估完成，确定算法和模型后，应当使用完整数据集再训练一遍，得到的模型才是最终呈现给用户的。

## 2.3 性能度量 Performance measure

性能度量是衡量模型泛化能力的评价标准。在对比不同模型的能力时，使用不同的性能度量往往导致不一样的结果。模型的好坏更多地取决于任务的需求。

回归任务中常用的是“均方误差（mean squared error）”：
$$
\Large E(f;D) = \cfrac1m\sum_{i=1}^{m}(f(\boldsymbol{x}_i) - y_i)^2
$$
如果引入数据分布和概率密度函数则为：
$$
\Large E(f; D)=\int_{\boldsymbol{x} \sim \mathcal{D}}(f(\boldsymbol{x})-y)^2p(\boldsymbol{x})d\boldsymbol{x}
$$

### 2.3.1 错误率与精度

错误率和精度常用于度量 **分类任务** 的性能。

错误率： 
$$
\Large E(f;D) = \cfrac1m\sum^m_{i=1}\Bbb{I}(f(\boldsymbol{x}_i) \neq y_i)
$$

精度：

$$
\Large
\begin{align}\begin{split}
acc(f;D) &=\cfrac1m\sum_{i=1}^m\Bbb{I}(f(\boldsymbol{x}_i) = y_i) \\
&= 1- E(f;D)
\end{split}\end{align}
$$
引入数据分布 $\Large \mathcal{D}$ 和概率密度函数 $\Large p(\cdot)$ 后，又可描述为：

错误率：
$$
\Large
E(f;D)=\int_{\boldsymbol{x} \to \mathcal{D}}\Bbb{I}(f(\boldsymbol{x}) \neq y)p(\boldsymbol{x})d\boldsymbol{x}
$$
精度：
$$
\Large
\begin{align}\begin{split}
acc(f;D) &= \int_{\boldsymbol{x} \to \mathcal{D}}\Bbb{I}(f(\boldsymbol{x}) = y)p(\boldsymbol{x})d\boldsymbol{x} \\
& = 1- E(f;D)
\end{split}\end{align}
$$

### 2.3.2 查准率、查全率与F1

还是以西瓜问题为例，倘若我们关心的是”模型挑出来的瓜中有多少确实是好瓜“或者”所有好瓜中有多少比例被挑选了出来“，这时错误率与精度就不够用了。

> 比如，一个模型挑出的瓜确实是好瓜，但是训练时”过拟合“了，导致数据集中还有一部分好瓜被误判成坏瓜了；模型的精度并不高，但是对于一些特定场景也够用了。

类似的需求在信息检索、web搜索中也经常出现，如在搜索时，我们关心”搜索出的信息中有多少比例是用户感兴趣的“，以及”有多少用户感兴趣的信息被搜索出来了“；这就引出了”**查准率（precision）**“与”**查全率（recall）**“。

这两个概念常用于分类问题，特别是二分类问题。

以二分类问题为例，下表是分类结果的”混淆矩阵“：

![img](https://cdn.astero.xyz/img/20200318232011377.png)

则查准率：
$$
\Large
P=\cfrac{TP}{TP+FP}
$$
查全率：
$$
\Large
R=\cfrac{TP}{TP+FN} = \cfrac{TP}{P}
$$
查准率与查全率是相互矛盾的度量，一个高则一个低；只有在一些简单的任务中，才会出现两者都很高的情况。

根据样本的预测结果进行排序，然后将测得的P，R数据作图可得 PR曲线/PR图。

![img](https://cdn.astero.xyz/img/20200318235306167.png)

一般来说，如果一条曲线将另一条曲线完全包住，则可断言前者的性能优于后者。

如果两条曲线有交叉，则需要通过平衡点（Break-Even Point，BEP）的值来判断，平衡点的值越大，性能越好。

> 在不同系统中对查准率和查全率的偏重不一样，如一般的推荐系统中对查准率的偏好更多，尽可能减少推荐错误的几率；而在逃犯信息检索系统中就更偏向查全率，希望尽可能不漏掉；

比平衡点更具体的是 $\Large F1$ 度量：
$$
\Large
F1 = \cfrac{2 \times P \times R}{P + R} = \cfrac{2 \times TP}{样例总数 + TP - TN}
$$
也即 $\Large P$ 和 $\Large R$ 的调和平均数：
$$
\Large 
\cfrac{1}{F1} = \cfrac12 \cdot(\cfrac1P + \cfrac1R)
$$
$\Large F1$ 度量的一般形式为 $\Large F_\beta$ ：
$$
\Large
F_\beta = \cfrac{(1+\beta^2) \times P \times R}{(\beta^2 \times P) + R}  \quad\quad\quad\quad
(\beta \gt 0)
$$
也即 $\Large P$ 和 $\Large R$ 的关于 $\Large \beta$ 的加权调和平均数。

> 当 $\Large \beta = 1$ 时，$\Large F1 = F_\beta$ ，查准率和查全率一样重要；
>
> 当 $\Large \beta \gt 1$ 时，查全率更重要；反之查准率更重要；

> 与算术平均和几何平均相比，调和平均数更重视数据中的较小值。
>
> 更多内容：[机器学习中的算术、几何、调和平均数](https://machinelearningmastery.com/arithmetic-geometric-and-harmonic-means-for-machine-learning/)

当拓展到多分类问题时，存在多个混淆矩阵，每个都可以计算出 $\Large P_i$ 和 $\Large R_i$ ，然后：

- 分别对其进行算术平均即可得到”宏查准率（$\rm{macro}-P$）“以及”宏查全率（$\rm{macro}-R$）“，并可以计算相应的 "宏F1（$\rm{macro}-F1$）"；
- 如果先计算混淆矩阵的各项平均值：$\Large \overline{TP}, \overline{FP}, \overline{TN}, \overline{FN}$ ，则也可以计算出”微查准率（$\rm{micro}-P$）“、”微查全率（$\rm{micro}-R$）“、”微F1（$\rm{micro}-F1$）“。

### 2.3.3 ROC与AUC

ROC曲线（Receiver Operating Characteristic Curve）和P-R曲线类似，只不过使用的值不同，ROC中使用的是”**真正例率TPR(True Positive Rate)**（也即查全率）“和”**假正例率FPR(False Positive Rate)**“作为坐标轴来绘制曲线。
$$
\Large
TPR = \cfrac{TP}{TP + FN} = \cfrac{TP}{P}
$$

$$
\Large
FPR = \cfrac{FP}{TN + FP}
$$



![img](https://cdn.astero.xyz/img/11525720-7eedb3ee87fa4111.jpg)

ROC曲线与FPR坐标轴围成的面积称为AUC(Area Under ROC Curve)，和PR曲线一样，可以通过ROC曲线的包含关系，以及AUC的面积大小来判断学习器的好坏。

> **讲得很清楚的文章链接：[如何理解ROC曲线](https://www.jianshu.com/p/2ca96fce7e81)**
>
> ROC曲线的横坐标和纵坐标其实是没有相关性的，所以不能把ROC曲线当做一个函数曲线来分析，应该把ROC曲线看成无数个点，每个点都代表一个分类器。
>
> ROC曲线描述的其实是分类器性能随着分类器阈值的变化而变化的过程。

根据上述的定义，其最直观的应用就是能反映模型在选取不同阈值的时候其敏感性（sensitivity, FPR）和其精确性（specificity, TPR）的趋势走向。不过，相比于其他的P-R曲线（精确度和召回率），ROC曲线有一个巨大的优势就是，当正负样本的分布发生变化时，其形状能够基本保持不变，而P-R曲线的形状一般会发生剧烈的变化，因此该评估指标能降低不同测试集带来的干扰，更加客观的衡量模型本身的性能。

> 此处略过AUC的计算以及损失函数的定义。

---

自己绘制的ROC，样本数量较少时呈现为多段线，当样本数量接近无穷时，会变成光滑的曲线。

![image-20210701150951506](https://cdn.astero.xyz/img/image-20210701150951506.png)

### 2.3.4 代价敏感错误与代价曲线

在现实任务中，$\Large FN$ 和 $\Large FP$ 的代价往往是不一样的，例如将一个健康人误诊为患者和将患者误诊为健康人的代价就完全不同；上面介绍的方法中，大都隐式地设置了均等代价。而现实中，我们要实现地并不是”**错误最少化**“而是”**代价最小化**“，将上面的混淆矩阵更换为”代价矩阵“，定义 $\Large cost_{ij}$ 表示将第 $\Large i$ 类误判为第 $\Large j$  类的代价来代替 $\Large 1$ 进行计算，就可以引入”代价曲线“。

![img](https://cdn.astero.xyz/img/20190511120729728.png)

---

在分类任务中，定义：

- $\Large cost_{ij}$ 表示将第 $\Large i$ 类样本预测为第 $\Large j$ 类样本的代价，其值越大，代表预测失败的损失越大；易知 $\Large cost_{ii} = 0$ ；

考虑二分类任务，令 $\Large D^+$ 和 $\Large D^-$ 分别代表样例集 $\Large D$ 中的正例子集和反例子集，则可定义”代价敏感错误率“为：
$$
\large
E(f;D;cost) = \cfrac1m(\sum_{\boldsymbol{x} \in D^+} \Bbb{I}(f(\boldsymbol{x}_i) \neq y_i) \times cost_{01} + \sum_{\boldsymbol{x} \in D^-} \Bbb{I}(f(\boldsymbol{x}_i) \neq y_i) \times cost_{10})
$$
将正例概率为 $\Large p$ 时的代价：
$$
\Large
P(+)cost=\cfrac{p \times cost_{01}}{p \times cost_{01} + (1-p) \times cost_{10}}
$$
将其作为 $\Large X$ 轴，计算此时的**归一化代价**（”总体错误率“更为贴切，即模型对于某一阈值的期望总体错误率）：
$$
\Large
\begin{align}\begin{split}
cost_{norm} &= \int_{p \in [0,1]} (FNR \cdot p + FPR \cdot(1-p)) \cdot dp \\
&= \cfrac{FNR \times p \times cost_{01} + FPR \times (1-p) \times cost_{10}}{p \times cost_{01} + (1-p) \times cost_{10}}
\end{split}\end{align}
$$
将其作为 $\Large Y$ 轴，构成代价平面。

将ROC曲线上的每个点 $\Large (FPR, TPR)$ 对应到代价平面上的两个点 $\Large (0, FPR)$ ，$\Large (1, 1-TPR)$ 构成的直线（原文中是线段），得到的结果如下图。每条直线代表一种阈值的取值。取所有被坐标轴截图线段的**下包络线**，与横轴之前的面积即为**模型对于所有阈值情况下的总体期望代价**。

> [知乎讲解链接 一定要看](https://www.zhihu.com/question/63492375/answer/247885093)，需要理解的点：
>
> - 为什么是直线而不是曲线：由于横轴是关于正例概率 $p$ 的非线性函数，相当于做了一次非线性缩放，把曲线拉直了。如果横轴用 $p$ 的话，根据纵轴的定义，就是一条曲线。
> - 如何理解归一化代价：引入代价后，进行了一次缩放，相当于错误率都乘以了代价的倍数，为方便比较不同任务中的模型，就需要进行归一；归一化的分母就是将所有情况全部预测错时的代价，因此归一化后小于1；（因此，如果只是争对一个任务中的多个模型进行比较，则无需进行归一。）
> - 归一化代价的本质时间上还是错误率，只是针对不同情况下的错误代价不同，做了一个非线性变换以及归一，因此也是可以进行比较的。

![img](https://cdn.astero.xyz/img/20190511120936632.png)

在不计入代价或代价相等时，就是ROC空间所描述的情形。

---

下面是对于同一组数据，$\Large cost_{10}$ 与 $\Large cost_{01}$ 的比值不同时的变化：

![image-20210701145859636](https://cdn.astero.xyz/img/image-20210701145859636.png)

![image-20210701145921685](https://cdn.astero.xyz/img/image-20210701145921685.png)

**CC相对于ROC的优势：**

- 代价可视化；即使在等价空间中，CC曲线可以通过纵轴直接查看错误率，比ROC更直观；
- 引入非等代价空间，更符合实际情况；
- **可以展示模型在各种 $\Large p$ 情况下的表现，因为先验概率与样本中的概率并不相同。**ROC曲线是在特定 $\Large p$ 下，而**期望总体代价**则可以视为对所有 $\Large p$ 的分布进行积分。如果可以确定 $\Large p \in D, D \in [0, 1]$，也可将横轴收窄为 $\Large D$ 的上下界。

CC曲线可以用来：

- **通过对比总体代价和不同正例概率下的代价来对比不同模型的性能；**
- **对比同一模型在不同分类阈值下的代价，进而找到最优的分类阈值；**

> [再贴一遍链接](https://www.zhihu.com/question/63492375/answer/247885093)

## 2.4 比较检验

通过性能度量对学习算法进行评估时，要明确的有：

- 我们希望比较的是**泛化性能**，而测得的是在测试集上评估出的性能；
- 测试集不同，测得的结果也不同；
- 相同的模型，相同的测试集，多次测试的结果也可能不一致；

假设检验（hypothesis test）可以提供统计意义上的泛化性能对比，以及对比结果的准确率。下面我们使用错误率 $\Large \epsilon$ 作为性能度量。

### 2.4.1 假设检验

假设检验中的”假设“是对学习算法泛化错误率分布的某种判断或猜想。现实中，我们并不知道其泛化错误率，只知道在测试集上的测试错误率 $\Large \hat\epsilon$ ，通常情况下 $\Large \epsilon \neq \hat \epsilon$ ，但是直观上两者应该很接近，因此，可以通过测试错误率，推断泛化错误率的分布。

---

#### 二项检验

假设一个学习算法的泛化错误率为 $\Large \epsilon$ ，在 $\Large m$ 个测试样本中测得的测试错误率为 $\Large \hat \epsilon$ ，即有 $\Large \hat \epsilon \times m$ 个样本被误分类。假设测试样本是从总体样本中独立采样而得，则在测试集中，学习算法将 $\Large m'$ 个样本误分类的情况的概率为：$\Large {m \choose {m'}}\epsilon^{m'} (1-\epsilon^{m-{m'}})$ ，当 $\Large m' = \hat \epsilon \times m$ 时，即泛化错误率 $\Large \epsilon$ 的学习算法被测得测试错误率 $\Large \hat \epsilon$ 的概率为：
$$
\Large
P(\hat \epsilon;\epsilon) = {m \choose {\hat \epsilon \times m}} \epsilon ^ {\hat \epsilon \times m} (1-\epsilon)^{m- \hat \epsilon \times m}
$$
是关于 $\Large \hat \epsilon$ 和 $\Large \epsilon$ 的二元函数，由于 $\Large \hat \epsilon$ 可知，对 $\Large \epsilon$ 求偏导，求解 $\Large \cfrac{\partial P}{\partial\; \epsilon} = 0$ ，可知 $\Large \epsilon = \hat \epsilon$ 时， $\Large P(\hat\epsilon;\epsilon)$ 最大，

且 $\Large |\epsilon - \hat \epsilon|$ 越小，$\Large P(\hat\epsilon;\epsilon)$ 越大，表现符合**二项分布（binomial）**的特征。

假设我们的目标泛化错误率是 $\Large \epsilon_0$，置信度为 $\Large 1-\alpha$ ,根据二项分布的计算公式可知：能观测到的最小错误率为：
$$
\Large
\overline \epsilon = min(\epsilon) \quad s.t. \sum^{m}_{i=\epsilon\times m + 1}
{m \choose i} \epsilon_o^i (1-\epsilon)^{m-i} \lt \alpha
$$
将测得的 $\Large \hat\epsilon$ 代入 $\Large \epsilon$ 进行计算，如果不满足，即测得的错误率小于临界错误率。也即：在$\Large 1- \alpha$ 的置信度下，学习器的泛化错误率不大于 $\Large \epsilon_0$ 。

> 推导过程参考[南瓜书](https://datawhalechina.github.io/pumpkin-book/#/chapter2/chapter2?id=_227)

---

#### t检验

正如我们从留出法推广到交叉验证法一样，我们也可以多次测试，得到多个 $\Large \hat \epsilon$ 。假设经过多次测试，得到了 $\Large k$ 个测试错误率：$\Large \hat \epsilon_1, \hat \epsilon_2,...,\hat\epsilon_k$ ，则平均错误率：
$$
\Large 
\mu = \cfrac1k\sum_{i=1}^k\hat\epsilon_i
$$
方差：
$$
\Large
\sigma^2=\cfrac{1}{k-1}\sum_{i=1}^k(\hat\epsilon_i - \mu)^2
$$
考虑到 $\Large k$ 个测试错误率是泛化错误率的独立采样，则：
$$
\Large
\tau_t = \cfrac{\sqrt{k}(\mu - \epsilon_0)}{\sigma}
$$
服从自由度为 $\Large k-1$ 的 $\Large t$ 分布，根据 $\Large t$ 分布的公式也能求解出在某一致信度下，泛化错误率不高于平均错误率$\Large \epsilon_0$ 。

### 2.4.2 交叉验证t检验

对两个学习算法的测试错误率做差后进行t检验，$\Large k$ 次测试后其错误率的差也服从$\Large t$ 分布，进行计算后即可得两个学习算法的泛化错误率优劣以及其致性度。

> 省略公式说明；
>
> 实际使用中常用 $5 \times 2$ 交叉验证法。

### 2.4.3 McNemar检验

对于二分类问题，使用**列联表**，定义 $\Large e_{AB}$ 表示算法$\Large A$ 分类正确而$\Large B$错误的样本数，则：
$$
\Large
\tau_{\chi^2}=\cfrac{(|e_{AB} - e_{BA}| - 1)^2}{e_{AB} + e_{BA}}
$$
 服从卡方分布（标准正态分布的平方），通过计算可以得出在一定置信度下，平均错误率较小的算法性能较优。

### 2.4.4 Friedman检验与Nemenyi检验

略

## 2.5 偏差与方差

要科学解释学习算法的泛化性能，需要利用到**偏差-方差分解（bias-vatiance decomposition）**。

---

假设对测试样本 $\Large \boldsymbol{x}$ ，令 $\Large y_D$ 为 $\Large \boldsymbol{x}$ 在 $\Large D$ 中的标记，$\Large y$ 为真实标记，$\Large f(\boldsymbol{x};D)$ 为训练集 $\Large D$ 上学得模型 $\Large f$ 在 $\Large \boldsymbol{x}$ 的预测输出，则学习算法的期望预测为：
$$
\Large
\overline f(\boldsymbol{x})=\Bbb{E}_D[f(\boldsymbol{x};D)]
$$
使用样本数相同的不同训练集时产生的方差为：
$$
\Large
var(\boldsymbol{x})=\Bbb{E}_D[(f(\boldsymbol{x};D) - \overline f(\boldsymbol{x}))^2]
$$
噪声为
$$
\Large
\xi = \Bbb{E} [(y_D-y)^2]
$$
期望输出与真实标记之间差别称为偏差：
$$
\Large
bias^2(\boldsymbol{x}) = (\overline f(\boldsymbol{x}) - y)^2
$$
假设噪声期望为 $\Large 0$ ，即 $\Large \Bbb{E}[y_D-y] = 0$ ，则对算法的期望泛化误差进行分解可得：
$$
\Large
\begin{align}\begin{split} 
E(f ; D)= & \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-y_{D}\right)^{2}\right] \\
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})+\bar{f}(\boldsymbol{x})-y_{D}\right)^{2}\right] \\ 
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y_{D}\right)^{2}\right] \\ 
&+\mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\left(\bar{f}(\boldsymbol{x})-y_{D}\right)\right] \\ 
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y_{D}\right)^{2}\right] \\ 
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y+y-y_{D}\right)^{2}\right] \\ 
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y\right)^{2}\right]+\mathbb{E}_{D}\left[\left(y-y_{D}\right)^{2}\right] \\ 
&+2 \mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y\right)\left(y-y_{D}\right)\right] \\ 
=& \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\left(\bar{f}(\boldsymbol{x})-y\right)^{2}+\mathbb{E}_{D}\left[\left(y_{D}-y\right)^{2}\right] 
\end{split}\end{align}
$$
即：
$$
\Large
E(f; D) = bias^2(\boldsymbol{x}) + var(\boldsymbol{x}) + \xi^2
$$

也即：

<p align="center" style="color:blue;">泛化误差可以分解为偏差，方差与噪声之和。</p>

> 推导过程：
>
> - 第1-2步：减一个$\bar{f}(\boldsymbol{x})$再加一个$\bar{f}(\boldsymbol{x})$，属于简单的恒等变形；
>
> - 第2-3步：首先将中括号里面的式子展开 
> $$
> \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}+\left(\bar{f}(\boldsymbol{x})-y_{D}\right)^{2}+2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\left(\bar{f}(\boldsymbol{x})-y_{D}\right)\right]
> $$
> 然后根据期望的运算性质：$\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]$可将上式化为 
> $$
> \mathbb{E}_{D}\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)^{2}\right]+\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y_{D}\right)^{2}\right] +\mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\left(\bar{f}(\boldsymbol{x})-y_{D}\right)\right]
> $$
> - 第3-4步：再次利用期望的运算性质将第3步得到的式子的最后一项展开
> $$
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\left(\bar{f}(\boldsymbol{x})-y_{D}\right)\right] = \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot\bar{f}(\boldsymbol{x})\right] \\ -  \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot y_{D}\right]
> $$
> - 首先计算展开后得到的第一项 
> $$
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot\bar{f}(\boldsymbol{x})\right] = \mathbb{E}_{D}\left[2f(\boldsymbol{x} ; D)\cdot\bar{f}(\boldsymbol{x})-2\bar{f}(\boldsymbol{x})\cdot\bar{f}(\boldsymbol{x})\right]
> $$
> 由于$\bar{f}(\boldsymbol{x})$是常量，所以由期望的运算性质：$\mathbb{E}[AX+B]=A\mathbb{E}[X]+B$（其中$A,B$均为常量）可得
> $$
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot\bar{f}(\boldsymbol{x})\right] = 2\bar{f}(\boldsymbol{x})\cdot\mathbb{E}_{D}\left[f(\boldsymbol{x} ; D)\right]-2\bar{f}(\boldsymbol{x})\cdot\bar{f}(\boldsymbol{x})
> $$
> 由公式（26）可知：$\mathbb{E}_{D}\left[f(\boldsymbol{x} ; D)\right]=\bar{f}(\boldsymbol{x})$，所以
> $$
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot\bar{f}(\boldsymbol{x})\right] = 2\bar{f}(\boldsymbol{x})\cdot\bar{f}(\boldsymbol{x})-2\bar{f}(\boldsymbol{x})\cdot\bar{f}(\boldsymbol{x})=0\
> $$
> - 接着计算展开后得到的第二项 
> $$
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot y_{D}\right]=2\mathbb{E}_{D}\left[f(\boldsymbol{x} ; D)\cdot y_{D}\right]-2\bar{f}(\boldsymbol{x})\cdot \mathbb{E}_{D}\left[y_{D}\right]
> $$
> 由于噪声和$f$无关，所以$f(\boldsymbol{x} ; D)$和$y_D$是两个相互独立的随机变量，所以根据期望的运算性质：$\mathbb{E}[XY]=\mathbb{E}[X]\mathbb{E}[Y]$（其中$X$和$Y$为相互独立的随机变量）可得 
> $$
> \begin{align} \begin{split}
> \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot y_{D}\right] &= 2\mathbb{E}_{D}\left[f(\boldsymbol{x} ; D)\cdot y_{D}\right]-2\bar{f}(\boldsymbol{x})\cdot \mathbb{E}_{D}\left[y_{D}\right] \\ 
> &=2\mathbb{E}_{D}\left[f(\boldsymbol{x} ; D)\right]\cdot \mathbb{E}_{D}\left[y_{D}\right]-2\bar{f}(\boldsymbol{x})\cdot \mathbb{E}_{D}\left[y_{D}\right] \\ 
> &=2\bar{f}(\boldsymbol{x})\cdot \mathbb{E}_{D}\left[y_{D}\right]-2\bar{f}(\boldsymbol{x})\cdot \mathbb{E}_{D}\left[y_{D}\right] \ &= 0 \end{split}\end{align}
> $$
> 所以 
> $$
> \begin{align}\begin{split} \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\left(\bar{f}(\boldsymbol{x})-y_{D}\right)\right] =& \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot\bar{f}(\boldsymbol{x})\right] \\ &- \mathbb{E}_{D}\left[2\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})\right)\cdot y_{D}\right] \\ =& 0+0 \\ =&0 \end{split}\end{align}
> $$
> - 第4-5步：同第1-2步一样，减一个$y$再加一个$y$，属于简单的恒等变形；
>
> - 第5-6步：同第2-3步一样，将最后一项利用期望的运算性质进行展开；
>
> - 第6-7步：因为$\bar{f}(\boldsymbol{x})$和$y$均为常量，所以根据期望的运算性质可知，第6步中的第2项可化为 
> $$
> \mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y\right)^{2}\right]=\left(\bar{f}(\boldsymbol{x})-y\right)^{2}
> $$
> 同理，第6步中的最后一项可化为 
> $$
> 2\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y\right)\left(y-y_{D}\right)\right]=2\left(\bar{f}(\boldsymbol{x})-y\right)\mathbb{E}_{D}\left[\left(y-y_{D}\right)\right]
> $$
> 由于此时假设噪声的期望为零，也即$\mathbb{E}_{D}\left[\left(y-y_{D}\right)\right]=0$，所以 
> $$
> 2\mathbb{E}_{D}\left[\left(\bar{f}(\boldsymbol{x})-y\right)\left(y-y_{D}\right)\right]=2\left(\bar{f}(\boldsymbol{x})-y\right)\cdot 0=0
> $$

总结：

- 偏差（29）：度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法**本身的拟合能力**；
- 方差（27）：度量了同样大小的训练集变化所导致的学习性能的变化，即**数据扰动带来的影响**；
- 噪声（28）：表达了学习算法在当前任务下的期望泛化误差的下界，即**问题本身的难度**；

偏差-方差分解说明：**泛化性能是由学习算法的能力，问题的难度以及数据的充分性共同决定的。**

> 一般来说，偏差与方差是相互矛盾的（bias-variancew dilemma）。如果拟合能力不强，则也不易受数据扰动影响；如果拟合能力过强，也易受扰动影响，且会发生过拟合。
