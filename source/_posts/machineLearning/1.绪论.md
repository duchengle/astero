---
title: 1. 绪论
date: 2021-06-05
categories: 
  - MachineLearning-周志华
tags:
  - readnotes
  - ml
---

## 1.1 引言

什么是机器学习 （machine learning）？

> <span style="color:green">傍晚小街路面上沁出微雨后的湿润，和煦的细风吹来，抬头看看天边的晚霞，嗯，明天又是一个好天气。走到水果摊前，挑了个根蒂蜷缩、敲起来声音浊响的青绿西瓜...</span>

上面这段话中， 有很多基于<span style="color:orange">**经验**</span>做的判断，如：根据晚霞和微风判断明天是个好天气；根据西瓜的根蒂形状、色泽、声音判断是个正熟的好瓜。这些经验，或是我们亲身经历过的，或是前人总结流传下来的；<span style="color:green">通过对经验的利用，我们就能对新情况做出有效的决策。</span>

那么，计算机能够像人类一样完成这个经验积累到实际利用的过程吗？

机器学习就是这样一门学科，致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中：<span style="color:orange">**经验**</span> = <span style="color:orange">**数据**</span>，因此，机器学习研究的主要内容，就是关于计算机从数据中产生<span style="color:green">**模型**</span>的算法，即<span style="color:red">**学习算法**</span>。机器学习就是研究关于<span style="color:red">**学习算法**</span>的学科。

> 假设用P来评估计算机在某任务T上的性能，若一个程序通过利用经验E，使得对同一个任务T，计算机的性能P得到了改善，那么我们称：关于T和P，该程序对E进行了学习。

## 1.2 基本术语

要进行机器学习，首先要有数据。以下是关于西瓜的一组数据

> (色泽=青绿; 根蒂=蜷缩; 敲声=浊响)
>
> (色泽=乌黑; 根蒂=稍蜷; 敲声=沉闷)
>
> (色泽=浅白; 根蒂=硬挺; 敲声=清脆)
>
> . . .

### 记录 Instance

关于某个对象或事件的一条数据称为记录，如上述描述中的每一行都是一条关于西瓜的记录。也称为<span style="color:green">**示例**</span>（instance），<span style="color:green">**样本**</span>（sample）。

### 属性/特征 Feature

Attribute/feature, 反映事件或对象在某方面的表现或性质的事项，如“色泽”、“敲声”，属性的值称为属性值。

### 属性空间/样本空间/输入空间

Attribute space/sample space，由属性张成的空间称为属性空间；如果把上述描述中的三个属性作为三个坐标轴，则它们张成了一个用于描述西瓜的三维空间，每条记录就是空间中的一个坐标，因此，一个示例也可称为一个**特征向量（feature vector）**；

### 数据集 Data set

一组记录的集合称为一个**数据集**（data set）；有时，整个数据集亦可称为整个样本空间中的一个**样本**采样；

$\Large{\mit{D}} = \{ \boldsymbol{\cal{x}}_1, \boldsymbol{\cal{x}}_2, ..., \boldsymbol{\cal{x}}_m \}$ 表示包含 $m$ 个示例的数据集。

### 维数 Dimensionality

一个实例拥有的属性数量称为**维数**，在这个例子中维数为3；

假设每个示例拥有 $\Large\cal{d}$ 个维数，则示例 $\Large\boldsymbol{\cal{x}}_i = (x_{i1}; x_{i2};...x_{id})$ 是 $\Large\cal{d}$ 维样本空间 $\Large\mathcal{X}$ 中的一个向量，$\Large\boldsymbol{\cal{x_i}} \in \Large\mathcal{X}$ 。

### 学习/训练 Learning/Training

从数据中学得模型得过程称为学习/训练，这个过程通过执行某个学习算法来完成。

### 标签 Label

要得到关于预测的模型，还需要知道示例数据的结果信息，例如：“示例一是好瓜”这种**标记**，拥有标记的示例称为**样例（example）**。

一般用 $\Large{ (\boldsymbol{x}_i,y_i) }$ 表示第 $\Large{i}$ 个样例，$\Large{y_i} \in \Large{\cal{Y}}$ 是示例 $\Large{\boldsymbol{x_i}}$ 的标记，$\Large{\cal{Y}}$ 是所有标记的集合，称为**标记空间（label space）**或输出空间。

### 分类 Classification

要预测的标签为离散值时（如：好瓜，坏瓜），这种学习任务称为<span style="color:green">**分类**</span>；

存在只有两种分类的二分类任务和多种类别的多分类任务；

### 回归 Regression

要预测的标签为连续值时（如：细化成熟度0.85，0.37），这种学习任务称为<span style="color:green">**回归**</span>； 

### 预测 Prediction

一般来说，预测任务是希望通过对训练集 $\Large{\{(\boldsymbol{x}_1, y_1), (\boldsymbol{x}_2, y_2),...,(\boldsymbol{x}_m, y_m) \}}$ 进行学习，建立一个从输入空间 $\Large\mathcal{X}$ 到输出空间 $\Large{\cal{Y}}$ 的映射 $\Large{f : \mathcal{X} \mapsto \cal{Y}}$

对于二分类任务，$\Large{ \cal{Y} = \{ -1, +1\}}$ 或 $\Large{\{0,1\}}$ ；

对于多分类任务，$\Large{|\; \cal{Y}\;| \gt 2}$ ；

对于回归任务，$\Large{\cal{Y} = \Bbb{R}}$，$\Large{\Bbb{R}}$ 为实数集。

### 聚类 Clustering

将训练集种的样本分为若干**簇（cluster）**。

- 簇是自动形成的，可能对应一些潜在的概念划分，有助于了解数据的内在规律。
- 通常来说，用于聚类的数据是不具有标记信息的；（半监督聚类除外）

### 监督学习 Supervised learning

训练数据带有标记信息，代表是分类和回归；

### 非监督学习 Unsupervised learning

训练数据不带标记信息，代表是聚类；

### 泛化与分布

用训练样本训练出的模型适用于“新样本（unseen instance）”的能力称为“**泛化能力（generalization）**”。

通常情况下，我们选取或采集的训练样本只是整个样本空间的一小部分采样；

假设整个样本空间服从未知分布 $\Large{\cal{D}}$ ，每个样本都是随机独立地采样获得的（independent and identically distributed，简称 $\Large{i, i, d}$）；当我们采集的样本越多，关于 $\Large{\cal{D}}$ 我们就能了解得越多，就越有可能通过学习获得具有强泛化能力得模型。

## 1.3 假设空间

> 归纳（induction）：从特殊到一般，从具体事实总结一般规律；
>
> 演绎（deduction）：从基础规律推演具体情况；

在一个简单的归纳学习的任务中（如本例），我们假设“好瓜”可由“色泽”，“根蒂”，“敲声”三个因素完全**确定**，且每种因素各有三种可能取值；

则学习的过程就是一个在所有“好瓜”的假设（hypothesis）组成的空间中进行搜索的过程，目的是找到于训练集数据匹配的一个或多个假设。

在本例中，假设空间的大小是每种属性的所有排列组合，共计 $ \Large{7 * 7 * 7 + 1 = 344}$ 种，这里的 $\Large{1}$ 是指压根就不存在“好瓜”这个概念。 

学习过程中，可以对基于训练集对假设空间进行多种策略的搜索，不断删除与正例不一致的假设以及与反例一致的假设；最终得到的就是与训练集一致的假设，也就是学习的结果。

现实问题种，由于假设空间巨大，学习的结果可能是多个假设，即**版本空间（version space）**。

>对于假设空间我们可以这样理解：机器学习包含很多种算法，比如线性回归、支持向量机、神经网络、决策树、GDBT等等。我们在建模的时候，第一步就是要选择一个特定的算法比如“支持向量机”。**一旦选择了一个算法，就相当于我们选择了一个假设空间。**在一个假设空间里，我们通常会有无数种不同的解（或者可以理解成模型），**一个优化算法（比如梯度下降法）做的事情就是从中选择最好的一个解或者多个解/模型**，当然优化过程要依赖于样本数据。举个例子，如果我们选择用支持向量机，那相当于我们可选的解/模型集中在上半部分（蓝色点）。
>
>![img](https://cdn.astero.xyz/img/v2-b16dfc4f554c08953a569537d385b47c_720w.jpg)

## 1.4 归纳偏好

假设学习完成后，还存在与训练集一致的多种模型，这那么该怎样判定选择那种假设作为最终输出的模型呢？

注意：模型最终只可能采用一种假设，否则就会出现对于同一个输入，多次运行产出了不一样的结果，这样就完全没有意义了。

这时，学习算法的偏好就会起到作用。算法可能偏好“尽可能特殊的模型”或“尽可能一般的模型”，抑或是基于对该问题的其他研究揭露的一部分假设，又或者是普适的一般规律，如：变化大都是连续的，而不是突然产生的，变化曲线应当趋于平缓。

“<span style="color:blue">**奥卡姆剃刀（Occam's razor）**</span>”也是常用的一种原则，即：<span style="color:green">*若有多种假设与观察一致，则选取最简单的那个*</span>。

> “如何判断两种假设哪一个更简单” 这个问题并不简单。

<span style="color:orange">事实上，假设存在两种基于不同的偏好得到的学习算法  $\Large\frak{L}_a$ 和 $\Large\frak{L}_b$ ，如果 $\Large\frak{L}_a$ 在一些问题上比 $\Large\frak{L}_b$ 要好，那么必然存在另一些问题使得 $\Large\frak{L}_b$ 要比 $\Large\frak{L}_a$ 要好。</span>

这是可以在数学上证明的，即**NFL(No Free Lunch Theorem)定理**。

简单证明过程：

---

假设：

1. 假设样本空间 $\Large\mathcal{X}$ 和假设空间 $\Large\cal{H}$ 都是离散的；
2. 令 $\Large{P(h|X,\frak{L}_a)}$ 代表算法 $\Large\frak{L}_a$ 基于训练数据 $\Large{X}$ 产生假设 $\Large{h}$ 的概率；
3. 令 $\Large{f}$ 代表我们期望的真实目标函数；

则：$\Large{\frak{L}_a}$ 的 “**训练集外误差**”，即 $\Large{\frak{L}_a}$ 在训练集外的所有样本上的误差为：
$$
\Large
E_{ote}(\frak{L}_a|\mit{X},f) = \sum_h \sum_{\boldsymbol{x} \in (\mathcal{X}-X)} 
P(\boldsymbol{x}) \;\; \Bbb{I}(\;h(x)\; \neq \;f(x))\;
P(h\;|\;X, \frak{L}_{\mit{a}})
$$
考虑二分类问题，且真实函数可以是任何函数 $\Large f: \; \mathcal{X} \mapsto \{0,1\}$ ，函数空间为 $\Large \{0,1\}^{|\mathcal{X}|}$ ，则对所有可能的 $\Large f$ 按照均匀分布，对误差求和可得：
$$
\Large
\begin{equation}\begin{split}
\sum_f E_{ote}(\frak{L}_a|\mit{X},f) &= \sum_f \sum_h \sum_{\boldsymbol{x}\in(\mathcal{X} - X)}
P(\boldsymbol{x}) \;\; \Bbb{I}(\;h(x)\; \neq \;f(x))\;
P(h\;|\;X, \frak{L}_{\mit{a}}) \\
&= \sum_{\boldsymbol{x}\in(\mathcal{X} - X)} P(\boldsymbol{x})\sum_hP(h\;|\;X,\frak{L}_{\mit{a}})
\sum_f \Bbb{I}(\mit{h}(\boldsymbol{x}) \neq f(\boldsymbol{x})) \\
&= \sum_{\boldsymbol{x}\in(\mathcal{X} - X)}P(\boldsymbol{x})\sum_hP(h \; | \; X, \frak{L}_{\mit{a}}) \cfrac{1}{2}2^{|\mathcal{X}|} \\
&= \cfrac{1}{2}2^{|\mathcal{X}|} \sum_{\boldsymbol{x}\in(\chi - X)} P(\boldsymbol{x}) 
\sum_h P(h\;|\;X, \frak{L}_{\mit{a}}) \\
&= 2^{|\mathcal{X}| - 1} \sum_{\boldsymbol{x}\in(\mathcal{X} - X)} P(\boldsymbol{x}) \;\cdot\;1
\end{split}\end{equation}
$$

> $\Large\frac{1}{2}$ 的来历： 若 $\Large f$ 属于均匀分布，则有一半的 $\Large f$ 对 $\Large \boldsymbol {x}$ 的预测与 $\Large h(\boldsymbol{x}) $ 不一致；

可以得知，总的误差和学习算法 $\Large\frak{L}$ 无关。也就是说，**不同学习算法的期望性能是相同的**！

---

推导过程：

$$
\begin{aligned} 
\sum_{f}E_{ote}(\mathfrak{L}_a\vert X,f) &= 
\sum_f \sum_h \sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x}))P(h\vert X,\mathfrak{L}_a) \\ 
&=\sum_{\boldsymbol{x}\in(\mathcal{X}-X)}P(\boldsymbol{x}) \sum_hP(h\vert X,\mathfrak{L}_a)\sum_f\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x})) \\
&=\sum_{\boldsymbol{x}\in(\mathcal{X}-X)}P(\boldsymbol{x}) \sum_hP(h\vert X,\mathfrak{L}_a)\cfrac{1}{2}2^{\vert \mathcal{X} \vert} \\ 
&=\cfrac{1}{2}2^{\vert \mathcal{X} \vert}\sum_{\boldsymbol{x}\in(\mathcal{X}-X)}P(\boldsymbol{x}) \sum_hP(h\vert X,\mathfrak{L}_a) \\
&=2^{\vert \mathcal{X} \vert-1}\sum_{\boldsymbol{x}\in(\mathcal{X}-X)}P(\boldsymbol{x}) \cdot 1 \\
\end{aligned}
$$
[解析]：第1步到第2步：
$$
\begin{aligned} 
&\sum_f\sum_h\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x}))P(h\vert X,\mathfrak{L}*a) \\ 
&=\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x})\sum_f\sum_h\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x}))P(h\vert X,\mathfrak{L}_a) \\ 
&=\sum_{\boldsymbol{x}\in\mathcal{X}-X}P(\boldsymbol{x}) \sum_hP(h\vert X,\mathfrak{L}_a)\sum_f\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x})) \ \end{aligned}
$$
第2步到第3步：首先要知道此时我们对$f$的假设是任何能将样本映射到{0,1}的函数且服从均匀分布，也就是说不止一个$f$且每个$f$出现的概率相等，例如样本空间只有两个样本时：$ \mathcal{X}={\boldsymbol{x}_1,\boldsymbol{x}_2},\vert \mathcal{X} \vert=2$，那么所有的真实目标函数$f$为：
$$
\begin{aligned} 
f_1:f_1(\boldsymbol{x}_1)=0,f_1(\boldsymbol{x}_2)=0;\\ f_2:f_2(\boldsymbol{x}_1)=0,f_2(\boldsymbol{x}_2)=1;\\ f_3:f_3(\boldsymbol{x}_1)=1,f_3(\boldsymbol{x}_2)=0;\\ f_4:f_4(\boldsymbol{x}_1)=1,f_4(\boldsymbol{x}_2)=1; \\
\end{aligned}
$$
一共$2^{\vert \mathcal{X} \vert}=2^2=4$个真实目标函数。所以此时通过算法$\mathfrak{L}_a$学习出来的模型$h(\boldsymbol{x})$对每个样本无论预测值为0还是1必然有一半的$f$与之预测值相等，例如，现在学出来的模型$h(\boldsymbol{x})$对$\boldsymbol{x}_1$的预测值为1，也即$h(\boldsymbol{x}_1)=1$，那么有且只有$f_3$和$f_4$与$h(\boldsymbol{x})$的预测值相等，也就是有且只有一半的$f$与它预测值相等，所以$\sum_f\mathbb{I}(h(\boldsymbol{x})\neq f(\boldsymbol{x})) = \cfrac{1}{2}2^{\vert \mathcal{X} \vert} $；第3步一直到最后显然成立。值得一提的是，在这里我们假设真实的目标函数$f$为“任何能将样本映射到{0,1}的函数且服从均匀分布”，但是实际情形并非如此，通常我们只认为能高度拟合已有样本数据的函数才是真实目标函数，例如，现在已有的样本数据为${(\boldsymbol{x}_1,0),(\boldsymbol{x}_2,1)}$，那么此时$f_2$才是我们认为的真实目标函数，由于没有收集到或者压根不存在${(\boldsymbol{x}_1,0),(\boldsymbol{x}_2,0)},{(\boldsymbol{x}_1,1),(\boldsymbol{x}_2,0)},{(\boldsymbol{x}_1,1),(\boldsymbol{x}_2,1)}$这类样本，所以$f_1,f_3,f_4$都不算是真实目标函数。

---

尽管我们证明了一个**随机乱猜的算法**和**经过精心训练的算法**在数学上的期望性能是相同的，但这并不意味着机器学习没有任何意义，因为我们进行上述证明的前提是：

<center><span style="color:orange">所有问题出现的机会相同，或者所有问题同等重要。</span></center>

但是实际情况种，我们只关心自己正在解决的问题或类似问题；并且，**对于选取的属性空间**，真实函数的分布并不一定满足均匀分布。

> 原文中并没有限定在给定的属性空间，此处为个人理解

所以，我们能从NFL中学到的是：

<p align="center" style="color:green">脱离实际情况和具体问题，空泛的谈论和比较不同的学习算法是毫无意义的。</p>

<p align="center" style="color:green">如果考虑所有的情况，则所有算法一样好。学习算法自身的归纳偏好与实际问题的匹配程度是至关重要的。</p>

## 1.5 发展历程

符号主义：基于逻辑表达

连接主义：基于神经网络

统计学习：

深度学习：基于多层神经网络，利用高性能的计算设备和大数据；

## 1.6 应用现状

